{
  "best_metric": 0.6561514195583596,
  "best_model_checkpoint": "./results/checkpoint-713",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 713,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014025245441795231,
      "grad_norm": 3.3675026893615723,
      "learning_rate": 1.9719495091164096e-05,
      "loss": 0.6999,
      "step": 10
    },
    {
      "epoch": 0.028050490883590462,
      "grad_norm": 1.2678983211517334,
      "learning_rate": 1.9438990182328193e-05,
      "loss": 0.6907,
      "step": 20
    },
    {
      "epoch": 0.04207573632538569,
      "grad_norm": 3.482034206390381,
      "learning_rate": 1.9158485273492287e-05,
      "loss": 0.6985,
      "step": 30
    },
    {
      "epoch": 0.056100981767180924,
      "grad_norm": 3.5845985412597656,
      "learning_rate": 1.8877980364656384e-05,
      "loss": 0.6778,
      "step": 40
    },
    {
      "epoch": 0.07012622720897616,
      "grad_norm": 1.2336558103561401,
      "learning_rate": 1.8597475455820478e-05,
      "loss": 0.6917,
      "step": 50
    },
    {
      "epoch": 0.08415147265077139,
      "grad_norm": 1.2765913009643555,
      "learning_rate": 1.8316970546984572e-05,
      "loss": 0.6887,
      "step": 60
    },
    {
      "epoch": 0.09817671809256662,
      "grad_norm": 5.578125476837158,
      "learning_rate": 1.803646563814867e-05,
      "loss": 0.6656,
      "step": 70
    },
    {
      "epoch": 0.11220196353436185,
      "grad_norm": 1.417936086654663,
      "learning_rate": 1.7755960729312764e-05,
      "loss": 0.6696,
      "step": 80
    },
    {
      "epoch": 0.12622720897615708,
      "grad_norm": 0.9876720905303955,
      "learning_rate": 1.7475455820476858e-05,
      "loss": 0.6725,
      "step": 90
    },
    {
      "epoch": 0.1402524544179523,
      "grad_norm": 2.19343900680542,
      "learning_rate": 1.7194950911640955e-05,
      "loss": 0.6539,
      "step": 100
    },
    {
      "epoch": 0.15427769985974754,
      "grad_norm": 1.4941116571426392,
      "learning_rate": 1.691444600280505e-05,
      "loss": 0.7113,
      "step": 110
    },
    {
      "epoch": 0.16830294530154277,
      "grad_norm": 1.7535231113433838,
      "learning_rate": 1.6633941093969146e-05,
      "loss": 0.6622,
      "step": 120
    },
    {
      "epoch": 0.182328190743338,
      "grad_norm": 2.224285840988159,
      "learning_rate": 1.635343618513324e-05,
      "loss": 0.6542,
      "step": 130
    },
    {
      "epoch": 0.19635343618513323,
      "grad_norm": 1.2997112274169922,
      "learning_rate": 1.6072931276297338e-05,
      "loss": 0.7007,
      "step": 140
    },
    {
      "epoch": 0.21037868162692847,
      "grad_norm": 1.2158958911895752,
      "learning_rate": 1.579242636746143e-05,
      "loss": 0.6515,
      "step": 150
    },
    {
      "epoch": 0.2244039270687237,
      "grad_norm": 3.8932483196258545,
      "learning_rate": 1.551192145862553e-05,
      "loss": 0.6658,
      "step": 160
    },
    {
      "epoch": 0.23842917251051893,
      "grad_norm": 2.3833017349243164,
      "learning_rate": 1.5231416549789621e-05,
      "loss": 0.6697,
      "step": 170
    },
    {
      "epoch": 0.25245441795231416,
      "grad_norm": 1.3071131706237793,
      "learning_rate": 1.4950911640953719e-05,
      "loss": 0.6449,
      "step": 180
    },
    {
      "epoch": 0.2664796633941094,
      "grad_norm": 1.7728854417800903,
      "learning_rate": 1.4670406732117813e-05,
      "loss": 0.654,
      "step": 190
    },
    {
      "epoch": 0.2805049088359046,
      "grad_norm": 0.7194586396217346,
      "learning_rate": 1.4389901823281908e-05,
      "loss": 0.6609,
      "step": 200
    },
    {
      "epoch": 0.29453015427769985,
      "grad_norm": 2.0548529624938965,
      "learning_rate": 1.4109396914446002e-05,
      "loss": 0.6127,
      "step": 210
    },
    {
      "epoch": 0.3085553997194951,
      "grad_norm": 1.3207110166549683,
      "learning_rate": 1.38288920056101e-05,
      "loss": 0.6823,
      "step": 220
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 2.6016998291015625,
      "learning_rate": 1.3548387096774194e-05,
      "loss": 0.6404,
      "step": 230
    },
    {
      "epoch": 0.33660589060308554,
      "grad_norm": 1.3993171453475952,
      "learning_rate": 1.3267882187938291e-05,
      "loss": 0.6411,
      "step": 240
    },
    {
      "epoch": 0.3506311360448808,
      "grad_norm": 1.2784757614135742,
      "learning_rate": 1.2987377279102385e-05,
      "loss": 0.6903,
      "step": 250
    },
    {
      "epoch": 0.364656381486676,
      "grad_norm": 0.7921404838562012,
      "learning_rate": 1.270687237026648e-05,
      "loss": 0.6805,
      "step": 260
    },
    {
      "epoch": 0.37868162692847124,
      "grad_norm": 5.096529006958008,
      "learning_rate": 1.2426367461430575e-05,
      "loss": 0.6979,
      "step": 270
    },
    {
      "epoch": 0.39270687237026647,
      "grad_norm": 4.380465984344482,
      "learning_rate": 1.2145862552594672e-05,
      "loss": 0.6165,
      "step": 280
    },
    {
      "epoch": 0.4067321178120617,
      "grad_norm": 1.424665927886963,
      "learning_rate": 1.1865357643758766e-05,
      "loss": 0.6352,
      "step": 290
    },
    {
      "epoch": 0.42075736325385693,
      "grad_norm": 1.150312066078186,
      "learning_rate": 1.1584852734922862e-05,
      "loss": 0.696,
      "step": 300
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 0.9767810702323914,
      "learning_rate": 1.1304347826086957e-05,
      "loss": 0.6907,
      "step": 310
    },
    {
      "epoch": 0.4488078541374474,
      "grad_norm": 1.8918918371200562,
      "learning_rate": 1.1023842917251053e-05,
      "loss": 0.67,
      "step": 320
    },
    {
      "epoch": 0.4628330995792426,
      "grad_norm": 0.9230719804763794,
      "learning_rate": 1.0743338008415147e-05,
      "loss": 0.7021,
      "step": 330
    },
    {
      "epoch": 0.47685834502103785,
      "grad_norm": 2.307621955871582,
      "learning_rate": 1.0462833099579244e-05,
      "loss": 0.686,
      "step": 340
    },
    {
      "epoch": 0.4908835904628331,
      "grad_norm": 1.8983540534973145,
      "learning_rate": 1.0182328190743338e-05,
      "loss": 0.6664,
      "step": 350
    },
    {
      "epoch": 0.5049088359046283,
      "grad_norm": 1.2112247943878174,
      "learning_rate": 9.901823281907434e-06,
      "loss": 0.6455,
      "step": 360
    },
    {
      "epoch": 0.5189340813464236,
      "grad_norm": 1.0266144275665283,
      "learning_rate": 9.62131837307153e-06,
      "loss": 0.6156,
      "step": 370
    },
    {
      "epoch": 0.5329593267882188,
      "grad_norm": 1.4824765920639038,
      "learning_rate": 9.340813464235625e-06,
      "loss": 0.65,
      "step": 380
    },
    {
      "epoch": 0.5469845722300141,
      "grad_norm": 1.7301305532455444,
      "learning_rate": 9.060308555399721e-06,
      "loss": 0.7125,
      "step": 390
    },
    {
      "epoch": 0.5610098176718092,
      "grad_norm": 1.355760097503662,
      "learning_rate": 8.779803646563817e-06,
      "loss": 0.6604,
      "step": 400
    },
    {
      "epoch": 0.5750350631136045,
      "grad_norm": 0.8991820812225342,
      "learning_rate": 8.49929873772791e-06,
      "loss": 0.6533,
      "step": 410
    },
    {
      "epoch": 0.5890603085553997,
      "grad_norm": 2.0070621967315674,
      "learning_rate": 8.218793828892006e-06,
      "loss": 0.6143,
      "step": 420
    },
    {
      "epoch": 0.603085553997195,
      "grad_norm": 4.043944358825684,
      "learning_rate": 7.938288920056102e-06,
      "loss": 0.6922,
      "step": 430
    },
    {
      "epoch": 0.6171107994389902,
      "grad_norm": 2.0092434883117676,
      "learning_rate": 7.657784011220198e-06,
      "loss": 0.6826,
      "step": 440
    },
    {
      "epoch": 0.6311360448807855,
      "grad_norm": 1.1145164966583252,
      "learning_rate": 7.377279102384292e-06,
      "loss": 0.6492,
      "step": 450
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 2.7680540084838867,
      "learning_rate": 7.096774193548388e-06,
      "loss": 0.6332,
      "step": 460
    },
    {
      "epoch": 0.6591865357643759,
      "grad_norm": 1.7316396236419678,
      "learning_rate": 6.816269284712484e-06,
      "loss": 0.6468,
      "step": 470
    },
    {
      "epoch": 0.6732117812061711,
      "grad_norm": 1.6031076908111572,
      "learning_rate": 6.5357643758765785e-06,
      "loss": 0.5963,
      "step": 480
    },
    {
      "epoch": 0.6872370266479664,
      "grad_norm": 1.7493056058883667,
      "learning_rate": 6.255259467040674e-06,
      "loss": 0.6499,
      "step": 490
    },
    {
      "epoch": 0.7012622720897616,
      "grad_norm": 2.362898111343384,
      "learning_rate": 5.97475455820477e-06,
      "loss": 0.6311,
      "step": 500
    },
    {
      "epoch": 0.7152875175315568,
      "grad_norm": 1.6341485977172852,
      "learning_rate": 5.694249649368865e-06,
      "loss": 0.6827,
      "step": 510
    },
    {
      "epoch": 0.729312762973352,
      "grad_norm": 2.5866711139678955,
      "learning_rate": 5.41374474053296e-06,
      "loss": 0.6619,
      "step": 520
    },
    {
      "epoch": 0.7433380084151473,
      "grad_norm": 2.6388072967529297,
      "learning_rate": 5.133239831697055e-06,
      "loss": 0.589,
      "step": 530
    },
    {
      "epoch": 0.7573632538569425,
      "grad_norm": 0.9642263054847717,
      "learning_rate": 4.85273492286115e-06,
      "loss": 0.6008,
      "step": 540
    },
    {
      "epoch": 0.7713884992987378,
      "grad_norm": 2.0524251461029053,
      "learning_rate": 4.572230014025246e-06,
      "loss": 0.6332,
      "step": 550
    },
    {
      "epoch": 0.7854137447405329,
      "grad_norm": 4.9785614013671875,
      "learning_rate": 4.291725105189341e-06,
      "loss": 0.6319,
      "step": 560
    },
    {
      "epoch": 0.7994389901823282,
      "grad_norm": 3.954730272293091,
      "learning_rate": 4.011220196353436e-06,
      "loss": 0.5888,
      "step": 570
    },
    {
      "epoch": 0.8134642356241234,
      "grad_norm": 4.570483207702637,
      "learning_rate": 3.730715287517532e-06,
      "loss": 0.6149,
      "step": 580
    },
    {
      "epoch": 0.8274894810659187,
      "grad_norm": 1.7113795280456543,
      "learning_rate": 3.450210378681627e-06,
      "loss": 0.6384,
      "step": 590
    },
    {
      "epoch": 0.8415147265077139,
      "grad_norm": 4.602607727050781,
      "learning_rate": 3.1697054698457223e-06,
      "loss": 0.6698,
      "step": 600
    },
    {
      "epoch": 0.8555399719495091,
      "grad_norm": 1.513035535812378,
      "learning_rate": 2.889200561009818e-06,
      "loss": 0.5815,
      "step": 610
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 4.460329055786133,
      "learning_rate": 2.6086956521739132e-06,
      "loss": 0.6054,
      "step": 620
    },
    {
      "epoch": 0.8835904628330996,
      "grad_norm": 1.9194393157958984,
      "learning_rate": 2.3281907433380085e-06,
      "loss": 0.5945,
      "step": 630
    },
    {
      "epoch": 0.8976157082748948,
      "grad_norm": 0.9168360233306885,
      "learning_rate": 2.0476858345021037e-06,
      "loss": 0.6298,
      "step": 640
    },
    {
      "epoch": 0.9116409537166901,
      "grad_norm": 1.9555456638336182,
      "learning_rate": 1.7671809256661992e-06,
      "loss": 0.6236,
      "step": 650
    },
    {
      "epoch": 0.9256661991584852,
      "grad_norm": 2.0869829654693604,
      "learning_rate": 1.4866760168302946e-06,
      "loss": 0.6462,
      "step": 660
    },
    {
      "epoch": 0.9396914446002805,
      "grad_norm": 5.0415425300598145,
      "learning_rate": 1.2061711079943899e-06,
      "loss": 0.6382,
      "step": 670
    },
    {
      "epoch": 0.9537166900420757,
      "grad_norm": 3.8029706478118896,
      "learning_rate": 9.256661991584853e-07,
      "loss": 0.6376,
      "step": 680
    },
    {
      "epoch": 0.967741935483871,
      "grad_norm": 2.365152359008789,
      "learning_rate": 6.451612903225807e-07,
      "loss": 0.6483,
      "step": 690
    },
    {
      "epoch": 0.9817671809256662,
      "grad_norm": 1.9718719720840454,
      "learning_rate": 3.6465638148667605e-07,
      "loss": 0.6245,
      "step": 700
    },
    {
      "epoch": 0.9957924263674615,
      "grad_norm": 2.710983991622925,
      "learning_rate": 8.415147265077139e-08,
      "loss": 0.6537,
      "step": 710
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.6561514195583596,
      "eval_f1": 0.5841232413880401,
      "eval_loss": 0.6418383121490479,
      "eval_precision": 0.6854504159992932,
      "eval_recall": 0.6561514195583596,
      "eval_runtime": 23.5865,
      "eval_samples_per_second": 26.88,
      "eval_steps_per_second": 3.392,
      "step": 713
    }
  ],
  "logging_steps": 10,
  "max_steps": 713,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1520429502873600.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
