{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b82ca6",
   "metadata": {},
   "source": [
    "# ðŸ§  NLP with Pre-trained Models\n",
    "\n",
    "This notebook demonstrates how to use pre-trained models for common NLP tasks using the Hugging Face `transformers` library and related tools.\n",
    "\n",
    "Don't forget to do `poetry add transformers torch peft`\n",
    "\n",
    "To use notebooks with poetry may also need to install jupyter kernel:\n",
    "```\n",
    "poetry add jupyter ipykernel\n",
    "poetry run python -m ipykernel install --name youarebot-quickstart --user --display-name youarebot-quickstart\n",
    "```\n",
    "\n",
    "install Jupyter VSCode plugins and reload VSCode (maybe)\n",
    "\n",
    "NOTE: running todays notebooks will download many big models (~1Gb or more) to your laptop, so be careful when running this if you're low on free disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d18a495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001d12be",
   "metadata": {},
   "source": [
    "## QQ: which NLP tasks do you know?\n",
    "Some examples:\n",
    "- Classification (sentiment and topic)\n",
    "- NER (entity extraction)\n",
    "- Translation\n",
    "- Summarization\n",
    "- Zero-shot classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef60c3a5",
   "metadata": {},
   "source": [
    "## 2. Text Classification Demo\n",
    "\n",
    "Let's classify the sentiment of some example sentences using a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230f07be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20ea0a3f4a7425d9ae3077bd432d3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a4cde2b8b64d789854707fefc97c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae4b8e1fdf248738bacb517a3457b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4a42486f1648f0bd06d3b9f5849cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I love using pre-trained models!\n",
      "Result: [{'label': 'POSITIVE', 'score': 0.9993071556091309}]\n",
      "\n",
      "Text: This product is terrible and I want a refund.\n",
      "Result: [{'label': 'NEGATIVE', 'score': 0.9997045397758484}]\n",
      "\n",
      "Text: This product is terrible and I want a refund.\n",
      "Result: [{'label': 'NEGATIVE', 'score': 0.9997045397758484}]\n",
      "\n",
      "Text: The movie was okay, not great but not bad either.\n",
      "Result: [{'label': 'POSITIVE', 'score': 0.9919201135635376}]\n",
      "\n",
      "Text: The movie was okay, not great but not bad either.\n",
      "Result: [{'label': 'POSITIVE', 'score': 0.9919201135635376}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sentiment classification examples\n",
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "texts = [\n",
    "    \"I love using pre-trained models!\",\n",
    "    \"This product is terrible and I want a refund.\",\n",
    "    \"The movie was okay, not great but not bad either.\"\n",
    "]\n",
    "for text in texts:\n",
    "    result = classifier(text)\n",
    "    print(f\"Text: {text}\\nResult: {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0173f0b1",
   "metadata": {},
   "source": [
    "## 3. Named Entity Recognition (NER) Demo\n",
    "\n",
    "Extract named entities from text using a pre-trained NER model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24bf10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b65cbdbdea4e36a3da5725251c99f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e006fb4b889e49f9a788f44ad021e6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429a04475cea45058dde0a8375f257cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8688435457548c388fcc247173dda0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/Users/aguschin/Library/Caches/pypoetry/virtualenvs/echobot-Fhr7ANK2-py3.13/lib/python3.13/site-packages/transformers/pipelines/token_classification.py:181: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n",
      "/Users/aguschin/Library/Caches/pypoetry/virtualenvs/echobot-Fhr7ANK2-py3.13/lib/python3.13/site-packages/transformers/pipelines/token_classification.py:181: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Apple is looking at buying U.K. startup for $1 billion.\n",
      "Entities: [{'entity_group': 'ORG', 'score': np.float32(0.9990897), 'word': 'Apple', 'start': 0, 'end': 5}, {'entity_group': 'LOC', 'score': np.float32(0.999718), 'word': 'U', 'start': 27, 'end': 28}, {'entity_group': 'LOC', 'score': np.float32(0.9987226), 'word': 'K', 'start': 29, 'end': 30}]\n"
     ]
    }
   ],
   "source": [
    "# NER example\n",
    "from transformers import pipeline\n",
    "ner = pipeline('ner', grouped_entities=True)\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
    "entities = ner(text)\n",
    "print(f\"Text: {text}\\nEntities: {entities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be6e95",
   "metadata": {},
   "source": [
    "## 4. Text Translation Demo\n",
    "\n",
    "Translate English text to French using a pre-trained translation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "649b0779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-base and revision a9723ea (https://huggingface.co/google-t5/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d022ca8bc5994439b391c88446228d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d66fba2e394537a413b003e67c64e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7ed3486cbc43ccb6d1a324122cf140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02a1ff1e0f142a38cb5fd9884b0cae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787fd2bd37f243679ea35819f253c05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Machine learning is amazing.\n",
      "French: L'apprentissage par machine est Ã©tonnant.\n"
     ]
    }
   ],
   "source": [
    "# Translation example\n",
    "from transformers import pipeline\n",
    "translator = pipeline('translation_en_to_fr')\n",
    "text = \"Machine learning is amazing.\"\n",
    "translation = translator(text)\n",
    "print(f\"Original: {text}\\nFrench: {translation[0]['translation_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62a1744",
   "metadata": {},
   "source": [
    "## 5. Summarization Demo\n",
    "\n",
    "Summarize a long text using a pre-trained summarization model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cca76f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8dd12ccad64633b5d510ac7f878782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4483274113fd4bb3a9b0348df8127058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583c3669656644e693cb438e988b5d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e5d3d044374e4f97bdb5692649e83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9307fcba4c48b999fa8d42f2022ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa2bca4ebea4a5e88cb1bdcab3f50c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:  Machine learning is a field of artificial intelligence that uses statistical techniques to give computer systems the ability to learn from data without being explicitly programmed . Machine learning algorithms build a model based on sample data\n"
     ]
    }
   ],
   "source": [
    "# Summarization example\n",
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline('summarization')\n",
    "long_text = (\n",
    "    \"Machine learning is a field of artificial intelligence that uses statistical techniques \"\n",
    "    \"to give computer systems the ability to learn from data, without being explicitly programmed. \"\n",
    "    \"It is seen as a part of artificial intelligence. Machine learning algorithms build a model \"\n",
    "    \"based on sample data, known as training data, in order to make predictions or decisions \"\n",
    "    \"without being explicitly programmed to do so.\"\n",
    ")\n",
    "summary = summarizer(long_text, max_length=40, min_length=10, do_sample=False)\n",
    "print(f\"Summary: {summary[0]['summary_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b658e855",
   "metadata": {},
   "source": [
    "## 6. Zero-shot Classification Demo\n",
    "\n",
    "Classify text into arbitrary categories using a zero-shot model like `facebook/bart-large-mnli`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29e9a0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e9ef7de94b4baca96b3230de6bc597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c448e962c02b48dcba120dc986d3eaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce27a2ba651841d7877a9545eb4d6446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe233ff39ff4d54b20097274edc1e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4f17ba0bf44ca4bd79e299c1c903c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e17d3f1fd849e6add3f5b9c44d0eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: This is a fantastic new phone with a great camera.\n",
      "Labels: ['technology', 'sports', 'politics', 'entertainment']\n",
      "Result: {'sequence': 'This is a fantastic new phone with a great camera.', 'labels': ['technology', 'entertainment', 'sports', 'politics'], 'scores': [0.8937835693359375, 0.09825354814529419, 0.006223480682820082, 0.0017393830930814147]}\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot classification example\n",
    "from transformers import pipeline\n",
    "zero_shot = pipeline('zero-shot-classification', model='facebook/bart-large-mnli')\n",
    "text = \"This is a fantastic new phone with a great camera.\"\n",
    "labels = [\"technology\", \"sports\", \"politics\", \"entertainment\"]\n",
    "result = zero_shot(text, candidate_labels=labels)\n",
    "print(f\"Text: {text}\\nLabels: {labels}\\nResult: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f9ce12",
   "metadata": {},
   "source": [
    "## 7. Text Generation Demo\n",
    "\n",
    "Generate text using a sequence-to-sequence model such as T5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85d873f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e5f1a870a1434298300b8310148b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e699fd466f064c8d8cdad69a27bb8b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2164861f32477f85e647510303acd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262c62d02d27438fb1769b17772a1e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7c1793c7984d8c8e2e52caa21222ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe1d9ec95d941b6a9621c4ee6b74747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Both `max_new_tokens` (=256) and `max_length`(=40) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=40) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: summarize: The quick brown fox jumps over the lazy dog. This sentence is often used to demonstrate fonts and test typewriters.\n",
      "Generated: sentence often used to demonstrate fonts and test typewriters .\n"
     ]
    }
   ],
   "source": [
    "# Text generation example with T5\n",
    "from transformers import pipeline\n",
    "generator = pipeline('text2text-generation', model='t5-small')\n",
    "prompt = \"summarize: The quick brown fox jumps over the lazy dog. This sentence is often used to demonstrate fonts and test typewriters.\"\n",
    "generated = generator(prompt, max_length=40)\n",
    "print(f\"Prompt: {prompt}\\nGenerated: {generated[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117b6843",
   "metadata": {},
   "source": [
    "## 8. Fine-tuning a Model with PEFT/LoRA (Overview & Example)\n",
    "\n",
    "Fine-tuning allows you to adapt a pre-trained model to your own data. PEFT (Parameter-Efficient Fine-Tuning) and LoRA (Low-Rank Adaptation) are modern techniques for efficient fine-tuning.\n",
    "\n",
    "- **PEFT**: Only a small subset of parameters are updated, reducing compute and memory needs.\n",
    "- **LoRA**: Injects trainable low-rank matrices into each layer, making fine-tuning lightweight.\n",
    "\n",
    "Below is a minimal example using the `peft` library (conceptual, not runnable as-is):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0795729",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'peft'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Minimal PEFT/LoRA fine-tuning example (conceptual)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpeft\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_peft_model, LoraConfig, TaskType\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForSequenceClassification\n\u001b[32m      5\u001b[39m model = AutoModelForSequenceClassification.from_pretrained(\u001b[33m'\u001b[39m\u001b[33mbert-base-uncased\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'peft'"
     ]
    }
   ],
   "source": [
    "# Minimal PEFT/LoRA fine-tuning example (conceptual)\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "lora_config = LoraConfig(task_type=TaskType.SEQ_CLS, r=8, lora_alpha=32, lora_dropout=0.1)\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "# Now peft_model can be trained as usual with your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843fa549",
   "metadata": {},
   "source": [
    "## 9. Limitations of Pre-trained NLP Models\n",
    "\n",
    "While pre-trained models are powerful, they have important limitations:\n",
    "\n",
    "- **Context window size**: Most models have a maximum input length (e.g., 512 or 1024 tokens). Longer texts are truncated or split.\n",
    "- **Domain-specific vocabulary**: Performance drops on specialized jargon or rare terms not seen during pre-training.\n",
    "- **Bias and fairness**: Models may reflect biases present in their training data.\n",
    "- **Need for fine-tuning**: For best results on your data, fine-tuning is often required.\n",
    "\n",
    "**Example:**\n",
    "- Try classifying a very long text or a text with medical/legal jargon and observe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b9eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitation demo: context window and domain vocabulary\n",
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "long_text = \" \".join([\"This is a sentence.\"] * 200)  # Exceeds most model limits\n",
    "specialized_text = \"The patient was administered 5mg of apixaban for atrial fibrillation.\"\n",
    "print(\"Long text classification:\")\n",
    "print(classifier(long_text))\n",
    "print(\"\\nMedical jargon classification:\")\n",
    "print(classifier(specialized_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youarebot-quickstart",
   "language": "python",
   "name": "youarebot-quickstart"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
