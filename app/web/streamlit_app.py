import os
import requests
import streamlit as st
from uuid import uuid4
from sklearn.metrics import accuracy_score, log_loss
import numpy as np

# Set env for MacOS watcher issue
os.environ["STREAMLIT_WATCHER_TYPE"] = "none"

st.set_page_config(initial_sidebar_state="collapsed")

st.markdown("# Echo bot ðŸš€ + Live Metrics")
st.sidebar.markdown("# Echo bot ðŸš€ + Live Metrics")

# Initialize state
if "dialog_id" not in st.session_state:
    st.session_state.dialog_id = str(uuid4())

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Type something"}]

if "probs" not in st.session_state:
    st.session_state.probs = []  # Store predicted probabilities

if "labels" not in st.session_state:
    st.session_state.labels = []  # Store simulated ground-truth labels

default_echo_bot_url = "http://orchestrator:8000"

with st.sidebar:
    if st.button("Reset"):
        st.session_state.clear()
        st.rerun()

    st.text_input("Bot URL", key="echo_bot_url", value=default_echo_bot_url, disabled=True)
    st.text_input("Dialog ID", key="dialog_id", disabled=True)

# Show conversation history
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# Input handling
if message := st.chat_input("Your message"):
    # User message
    user_msg = {"role": "user", "content": message}
    st.session_state.messages.append(user_msg)
    st.chat_message("user").write(message)
    st.write(f"DEBUG dialog_id: {st.session_state.dialog_id}")

    # Call FastAPI `/predict` to get bot probability
    try:
        predict_response = requests.post(
            f"{default_echo_bot_url}/predict",
            json={
                "id": str(uuid4()),
                "dialog_id": st.session_state.dialog_id,
                "participant_index": 0,
                "text": message
            }
        )
        st.write(f"DEBUG predict status: {predict_response.status_code}")
        st.write(f"DEBUG predict response: {predict_response.text}")
        
        if predict_response.status_code == 200:
            predict_data = predict_response.json()
            is_bot_prob = predict_data.get("is_bot_probability", 0.5)
        else:
            st.error(f"Predict API error: {predict_response.status_code} - {predict_response.text}")
            is_bot_prob = 0.5
    except Exception as e:
        st.error(f"Error calling predict API: {str(e)}")
        is_bot_prob = 0.5

    # Call FastAPI `/get_message` to get LLM response
    try:
        response = requests.post(
            f"{default_echo_bot_url}/get_message",
            json={
                "dialog_id": st.session_state.dialog_id,
                "last_message_id": None,  # Optional: Fill if needed
                "last_msg_text": message
            }
        )
        st.write(f"DEBUG get_message status: {response.status_code}")
        st.write(f"DEBUG get_message response: {response.text}")
        
        if response.status_code == 200:
            response_data = response.json()
            reply_text = response_data.get("new_msg_text", "âŒ No reply")
        else:
            st.error(f"Get message API error: {response.status_code} - {response.text}")
            reply_text = "âŒ API Error"
    except Exception as e:
        st.error(f"Error calling get_message API: {str(e)}")
        reply_text = "âŒ Connection Error"

    # Show probability next to user msg
    st.write(f"ðŸ¤– BOT probability for your msg: {is_bot_prob:.2f}")
    st.session_state.probs.append(is_bot_prob)
    st.session_state.labels.append(0)  # User = human = 0

    # Bot reply from LLM
    bot_msg = {"role": "assistant", "content": reply_text}
    st.session_state.messages.append(bot_msg)
    st.chat_message("assistant").write(reply_text)

    st.rerun()

# Compute metrics if at least one turn
if len(st.session_state.probs) > 0:
    preds = [1 if p >= 0.5 else 0 for p in st.session_state.probs]
    acc = accuracy_score(st.session_state.labels, preds)
    try:
        ll = log_loss(st.session_state.labels, st.session_state.probs)
    except ValueError:
        ll = np.nan

    st.sidebar.markdown(f"**Live Accuracy:** {acc:.2f}")
    st.sidebar.markdown(f"**Live Log-Loss:** {ll:.2f}")

    # Plot metrics as line chart vs dialogue turn
    accuracy_progress = []
    logloss_progress = []

    num_dialogues = len(st.session_state.probs)
    for i in range(1, num_dialogues + 1):
        preds_so_far = [1 if p >= 0.5 else 0 for p in st.session_state.probs[:i]]
        acc_so_far = accuracy_score(st.session_state.labels[:i], preds_so_far)
        try:
            ll_so_far = log_loss(st.session_state.labels[:i], st.session_state.probs[:i])
        except ValueError:
            ll_so_far = np.nan
        accuracy_progress.append(acc_so_far)
        logloss_progress.append(ll_so_far)

    st.line_chart({
        "Accuracy": accuracy_progress,
        "LogLoss": logloss_progress
    })